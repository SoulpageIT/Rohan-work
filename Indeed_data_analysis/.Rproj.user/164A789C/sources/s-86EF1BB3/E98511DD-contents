---
title: "Indeed Employee Review data analysis of company Northwestern Mutual "
output: html_notebook
---
libraries used.
```{r}
#install.packages("pacman")
library(pacman)
library(viridis)
library(ggridges)
library(igraph)
library(highcharter)
#install.packages("ggraph")
library(ggraph)
library(ggplot2)
library(plotly)
#install.packages("tm")
library(tm)
#install.packages("tidyquant")
#library(tidyquant)
#install.packages(tidytext)
library(tidytext)
#install.packages("RTextTools")
#install.packages("RTextTools", repos = "http://r.findata.org")
#install.packages("RTextTools", dependencies=TRUE, repos='http://cran.rstudio.com/')
#install.packages('RTextTools',repos='http://cran.us.r-project.org')
library(SnowballC)
library(topicmodels)
library(ggthemes)
#install.packages("waff")
#library(waff)
library(grid)
library(gridExtra)
#install.packages("textreadr")
library(textreadr)
#install.packages("xml2",'https://cran.rstudio.com/bin/windows/contrib/3.5/xml2_1.2.0.zip')
library(purrr)
library(xml2)
library(stringr)
#install.packages("rvest")
library(rvest)
library(plyr)
library(tibble)
library(wordcloud)
library(syuzhet)
library(dplyr)
```

Data Mining from Indeed Website
```{r}
ht<-list(c())
n=seq(0,2835,20)
for(i in n){
y=read_html(paste("https://www.indeed.co.in/cmp/Northwestern-Mutual/reviews?fcountry=ALL&start=i"))%>% html_nodes(".cmp-review-text")%>%html_text(trim = TRUE)
ht<-append(ht,x)
FCA_html<-ht
}
FCA_html<-ht
```


```{r}
#Data-Preprocessing: removing '\n'
FCA_html<-gsub("\n","",FCA_html)
#remove all round brackets
FCA_html<-FCA_html%>%str_replace_all("\\(|\\)", "")
#remove all \\
FCA_html<-FCA_html%>%str_replace_all("\\\\", "")
#remove all non words and non numbers
#FCA_html<-FCA_html%>%str_replace_all("[^A-Za-z0-9]", "")
#remove all • 
FCA_html<-FCA_html%>%str_replace_all("\\•  ", "")
#remove all & 
FCA_html<-FCA_html%>%str_replace_all("\\ & ", "")
#remove all  non printable words
FCA_html<-FCA_html%>%str_replace_all("[^[:print:]]", "")
#remove all \
FCA_html<-FCA_html%>%str_replace_all(pattern = "\"", replacement = "")
#FCAindeed2<-FCAindeed2%>%stringi::stri_unescape_unicode()
# remove digits
#FCA_html%>%str_replace_all(pattern = "[[:digit:]]+", replacement = "")
#tm::removeNumbers(FCA_html)
#### pattern for dates
pattern ="\\(?\\d{4}\\)?[.-]? *\\d{2}[.-]? *[.-]?\\d{2}"
date=FCA_html%>%str_extract_all(pattern)
#FCA_html[[1]]%>%str_subset(pattern = "([0-9]{1,2})[- .]([a-zA-Z]+)[- .]([0-9]{4})")
#FCA_html[[1]]
#unlist(Date)
#FCA_html_2=data_frame(Date=as.Date(unlist(date)),FCA_html)

```


```{r}
get_sentiments(lexicon = "nrc")
```

```{r}
indeed <- tibble(text = c(FCA_html))
```

```{r}
#convert all text to lower case
df_lower<- tolower(indeed$text)

# Replace blank space (“rt”)
df_lower <- gsub("rt", "", df_lower)

# Replace @UserName
df_lower <- gsub("@\\w+", "", df_lower)

# Remove punctuation
df_lower <- gsub("[[:punct:]]", "", df_lower)

# Remove links
df_lower <- gsub("http\\w+", "", df_lower)

# Remove tabs
df_lower<- gsub("[ |\t]{2,}", "", df_lower)

# Remove blank spaces at the beginning
df_lower <- gsub("^ ", "", df_lower)

# Remove blank spaces at the end
df_lower <- gsub(" $", "",df_lower )
```

```{r}
#clean up by removing stop words
corpus<-Corpus(VectorSource(df_lower))
corpus <- tm_map(corpus, function(x)removeWords(x,stopwords()))
```

```{r}
#generate wordcloud
wordcloud(corpus,min.freq = 10,colors=brewer.pal(8, "Dark2"),random.color = TRUE,max.words = 500)
```
```{r}
#getting emotions using in-built function
mysentiment<-get_nrc_sentiment((df_lower))
```


```{r}
#calculationg total score for each sentiment
Sentimentscores<-data.frame(colSums(mysentiment[,]))
names(Sentimentscores)<-"Score"
Sentimentscores<-cbind("sentiment"=rownames(Sentimentscores),Sentimentscores)
rownames(Sentimentscores)<-NULL
```

```{r}
#plotting the sentiments with scores
ggplotly(ggplot(data=Sentimentscores,aes(x=reorder(sentiment,Score),y=Score))+geom_bar(aes(fill=sentiment),stat = "identity")+
  theme(legend.position="none")+
  xlab("Sentiments")+ylab("scores")+ggtitle("Sentiments of Employees behind the comments or rating ")+labs(title = "Sentiments of people behind the tweets on #MachineLearning",x="Sentiments", y = "Scores")+theme(plot.title = element_text(hjust = -10,face = "bold",color = "black"))+coord_flip())
```
Finding the words count in the text data.
```{r}
dtm <- TermDocumentMatrix(corpus)
m <- as.matrix(dtm)
v <- sort(rowSums(m),decreasing=TRUE)
d <- data.frame(word = names(v),freq=v)
d<- d[with(d,order(-freq)),]
head(d, 20)
```

showing the top 10 high frequency words  used in the text.
```{r}
ggplotly(ggplot(d[1:10,],aes(x=reorder(word,freq),y=freq,fill=as.factor(word)))+geom_bar(stat = "identity")+ geom_text(aes(label=freq), vjust=10)+labs(title = "The Top 10 frequently used words",x="Words", y = "Frequency of Words",fill="Words")+theme(plot.title = element_text(hjust = -10,face = "bold",color = "black"))+coord_flip())
```


```{r}
library(data.table)
d<-as.data.table(d)
p <- d[1:10,] %>%
 group_by(word) %>%
 plot_ly(labels = ~word, values = ~d[1:10,freq]) %>%
 add_pie(hole = 0.6) %>%
 layout(title = "The Percentage of top 10 frequently occuring words.",  showlegend = F,
         yaxis = list(showgrid = FALSE, zeroline = FALSE, showticklabels = FALSE))
p
```





