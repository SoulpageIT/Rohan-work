library("Sub_Division_IMD_2017.csv")
library(data.table)
library(data.table)
library(data.table)
data<-fread("Sub_Division_IMD_2017.csv")
View(data)
data<-fread("Sub_Division_IMD_2017.csv",stringsAsFactors = T)
summary(data)
library(data.table)
library(ggplot2)
library(plotly)
#install.packages("fpp")
library(fpp)
library(forecast)
data<-fread("Sub_Division_IMD_2017.csv",stringsAsFactors = T)
summary(data)
data_clean = data[complete.cases(data),]
data_na = data[!complete.cases(data),]
data_na
colnames(data)
rain_fall<-ts(data_clean[SUBDIVISION=="Bihar",c("YEAR","ANNUAL")],start = c(min(data_clean$YEAR)),end = c(max(data_clean$YEAR)),frequency=12)
autoplot(melsyd[,"Economy.Class"]) +
ggtitle("Economy class passengers: Melbourne-Sydney") +
xlab("Year") +
ylab("Thousands")
autoplot(rain_fall) +
ggtitle("Antidiabetic drug sales") +
ylab("$ million") +
xlab("Year")
autoplot(rain_fall) +
ggtitle("Antidiabetic drug sales") +
ylab("$ million") +
xlab("Year")
plot(diff(rain_fall))
plot(rain_fall)
max(data$YEAR)
as.ts(data_clean)
library(MASS)
library(caTools)
data(Boston)
View(Boston)
?Boston
library(data.table)
library(ggplot2)
library(plotly)
#install.packages("fpp")
library(fpp)
library(forecast)
data<-fread("Sub_Division_IMD_2017.csv",stringsAsFactors = T)
summary(data)
data_clean = data[complete.cases(data),]
data_na = data[!complete.cases(data),]
data_na
colnames(data)
rain_fall<-ts(data_clean[SUBDIVISION=="Bihar",c("YEAR","ANNUAL")],start = c(min(data_clean$YEAR)),end = c(max(data_clean$YEAR)),frequency=12)
autoplot(melsyd[,"Economy.Class"]) +
ggtitle("Economy class passengers: Melbourne-Sydney") +
xlab("Year") +
ylab("Thousands")
y <- ts(data_clean[SUBDIVISION=="Bihar",c("YEAR","ANNUAL")], start=min(data_clean$YEAR), frequency=12)
View(y)
autoplot(y) +
ggtitle("Antidiabetic drug sales") +
ylab("$ million") +
xlab("Year")
autoplot(y) +
ggtitle("Antidiabetic drug sales") +
ylab("$ million") +
xlab("Year")
plot(diff(y))
plot(y)
autoplot(y) +
ggtitle("Antidiabetic drug sales") +
ylab("Annual Rain Fall") +
xlab("Year")
autoplot(y) +
ggtitle("Annual Rain Fall by Year") +
ylab("Annual Rain Fall") +
xlab("Year")
library(data.table)
#install.packages("igraph")
library(igraph)
#install.packages("ggraph")
library(ggraph)
#install.packages("plotly")
library(plotly)
#install.packages("grid")
library(grid)
#install.packages("gridExtra")
library(gridExtra)
#install.packages("tidyquant")
#install.packages("lubridate")
#library(lubridate)
#install.packages("stringi")
library(tidyquant)
#install.packages("tm")
library(tm)
#install.packages("ggplot2")
library(ggplot2)
#install.packages("pacman")
#install.packages("lubridate")
pacman::p_load(tidyverse,tidytext,viridis,rvest,tm,wordcloud,SnowballC,tidyquant,ggridges,scales,highcharter,topicmodels)
# Get the files names
files = list.files(pattern="*.csv")
# First apply read.csv, then rbind
data = do.call(rbind, lapply(files, function(x) fread(x, stringsAsFactors = FALSE)))
clean_data<-na.omit(data)
names(clean_data)[names(clean_data) == 'V1'] <- 'No'
names(clean_data)[names(clean_data) == 'V2'] <- 'text'
names(clean_data)[names(clean_data) == 'V3'] <- 'date'
clean_data$month<-as.factor(month(as.POSIXct(clean_data$date)))
clean_data$weekDays<-as.factor(wday(clean_data$date, label=TRUE))
tidy <- clean_data %>%
unnest_tokens(word, text) %>%
add_count(date) %>%
dplyr::rename(date_total = n)
#remove stop words
data("stop_words")
tidy <- tidy %>%
anti_join(stop_words)
stop_user=c("linklink","whatsappshar","auburn","twittershar","edit","delet","via","edit","delet","via","starstarstarstarstarwork","pdt","hill","ago",
"facebookshar")
stop_user2=tibble(word=stop_user)
sentiment <- tidy %>%
inner_join(get_sentiments("bing"))
t<-list(
family="sans serif",
size=14,
color='black'
)
p <- sentiment %>%
group_by(sentiment) %>%
summarize(count = n()) %>%
plot_ly(labels = ~sentiment, values = ~count) %>%
add_pie(hole = 0.6) %>%
layout(title ,  showlegend = T,font=t,
xaxis = list(showgrid = FALSE, zeroline = FALSE, showticklabels = FALSE),
yaxis = list(showgrid = FALSE, zeroline = FALSE, showticklabels = FALSE))
p
sentiment<-as.data.table(sentiment)
p<-ggplotly(ggplot(sentiment[,.N,by=c("sentiment","month")], aes(x=month, y=N, group=sentiment)) +
geom_line(aes(color=sentiment))+
geom_point(aes(color=sentiment))+labs(x = "Months",y="Number of Words",
title = "Monthly Analysis of Sentiments in Head Lines")+theme(plot.title = element_text(hjust = -10,face = "bold",color = "black",size = 10)))
p
sentiment<-as.data.table(sentiment)
p<-ggplotly(ggplot(sentiment[,.N,by=c("sentiment","weekDays")], aes(x=weekDays, y=N, group=sentiment)) +
geom_line(aes(color=sentiment))+
geom_point(aes(color=sentiment))+labs(x = "WeekDays",y="Number of Words",
title = "Weekly Analysis of Sentiments in Head Lines")+theme(plot.title = element_text(hjust = -10,face = "bold",color = "black",size = 10)))
p
p<-clean_data %>%
unnest_tokens(word, text)%>%
inner_join(get_sentiments("bing"))
p%>%
count(word, sentiment, sort = TRUE) %>%
reshape2::acast(word ~ sentiment, value.var = "n", fill = 0) %>%
comparison.cloud(colors = viridis_pal(option = "D")(2),
max.words = 100)
q<-sentiment %>%
count(sentiment, word) %>%
group_by(sentiment) %>%
top_n(10) %>%
ungroup %>%
mutate(word = reorder(word, n)) %>%
mutate(sentiment = as.factor(sentiment))
p<-q%>%
ggplot(aes(word, n, fill = sentiment)) +
geom_col(alpha = 0.8, show.legend = FALSE) +
coord_flip() +
scale_y_continuous(expand = c(0,0)) +
facet_wrap(~sentiment,scales="free") +
labs(y = "Total number of occurrences", x = "",title = "Frequency of Words occured in sentiments")+
#scale_fill_manual(values=viridis_pal(option = "D")(8))+
theme(plot.title = element_text(hjust = -10,face = "bold",color = "black",size = 10))+
scale_fill_viridis(end = 0.75, discrete=TRUE, direction = -1) +
scale_x_discrete(expand=c(0.02,0))  +
# strip horizontal  axis labels
theme(axis.title.x=element_blank()) +
theme(axis.ticks.x=element_blank()) +
theme(axis.text.x=element_blank())+
theme_minimal(base_size = 13)
ggplotly(p)
sentiment <- tidy %>%
inner_join(get_sentiments("nrc"))
p <- sentiment %>%
group_by(sentiment) %>%
summarize(count = n()) %>%
plot_ly(labels = ~sentiment, values = ~count) %>%
add_pie(hole = 0.6) %>%
layout(showlegend = T,
xaxis = list(showgrid = FALSE, zeroline = FALSE, showticklabels = FALSE),
yaxis = list(showgrid = FALSE, zeroline = FALSE, showticklabels = FALSE))
p
sentiment <- tidy %>%
inner_join(get_sentiments("nrc"))
sentiment<-as.data.table(sentiment)
p<-ggplotly(ggplot(sentiment[,.N,by=c("sentiment","month")], aes(x=month, y=N, group=sentiment)) +
geom_line(aes(color=sentiment))+
geom_point(aes(color=sentiment))+labs(x = "Months",y="Number of Words",
title = "Monthly Analysis of Sentiments in Head Lines")+theme(plot.title = element_text(hjust = -10,face = "bold",color = "black",size = 10)))
p
sentiment<-as.data.table(sentiment)
p<-ggplotly(ggplot(sentiment[,.N,by=c("sentiment","weekDays")], aes(x=weekDays, y=N, group=sentiment)) +
geom_line(aes(color=sentiment))+
geom_point(aes(color=sentiment))+labs(x = "WeekDays",y="Number of Words",
title = "Weekly Analysis of Sentiments in Head Lines")+theme(plot.title = element_text(hjust = -10,face = "bold",color = "black",size = 10)))
p
p<-clean_data %>%
unnest_tokens(word, text)%>%
inner_join(get_sentiments("nrc")) %>%
count(word, sentiment, sort = TRUE)
p%>%
filter(sentiment %in% c("negative","positive","joy","sadness"))%>%
reshape2::acast(word ~ sentiment, value.var = "n", fill = 0)%>%
comparison.cloud(colors = viridis_pal(option = "D")(4),
max.words = 200)
p<-sentiment %>%
count(sentiment, word) %>%
filter(sentiment %in% c("positive", "negative",
"joy", "trust","fear","sadness")) %>%
group_by(sentiment) %>%
top_n(10) %>%
ungroup %>%
mutate(word = reorder(word, n)) %>%
mutate(sentiment = as.factor(sentiment))
d<-p %>%
ggplot(aes(word, n, fill = sentiment)) +
geom_bar(alpha = 0.8, show.legend = FALSE,stat = "identity") +
coord_flip() +
scale_y_continuous(expand = c(0,0)) +
facet_wrap(~sentiment, scales = "free") +
labs(y = "Total number of occurrences", x = "Words",title = "Frequency of Words occured in sentiments")+theme_bw()+
scale_fill_manual(values=viridis_pal(option = "D")(6))
ggplotly(d)
data(stop_words)
tidy_descr<-clean_data %>%
unnest_tokens(word, text) %>%
mutate(word=removeNumbers(word))%>%
mutate(word_stem = wordStem(word)) %>%
anti_join(stop_words, by = "word") %>%
filter(!word_stem %in% stop_words$word) %>%
filter(!word_stem %in% stop_user)
tidy_descr %>%
count(word_stem) %>%
mutate(word_stem = removeNumbers(word_stem)) %>%
with(wordcloud(word_stem, n, max.words = 100, colors = palette_light()))
library(data.table)
#install.packages("igraph")
library(igraph)
#install.packages("ggraph")
library(ggraph)
#install.packages("plotly")
library(plotly)
#install.packages("grid")
library(grid)
#install.packages("gridExtra")
library(gridExtra)
#install.packages("tidyquant")
#install.packages("lubridate")
#library(lubridate)
#install.packages("stringi")
library(tidyquant)
#install.packages("tm")
library(tm)
#install.packages("ggplot2")
library(ggplot2)
#install.packages("pacman")
#install.packages("lubridate")
pacman::p_load(tidyverse,tidytext,viridis,rvest,tm,wordcloud,SnowballC,tidyquant,ggridges,scales,highcharter,topicmodels)
ggseasonplot(y, year.labels=TRUE, year.labels.left=TRUE) +
ylab("$ million") +
ggtitle("Seasonal plot: antidiabetic drug sales")
library(data.table)
library(ggplot2)
library(plotly)
#install.packages("fpp")
library(fpp)
library(forecast)
library(data.table)
library(ggplot2)
library(plotly)
#install.packages("fpp")
library(fpp)
library(forecast)
data<-fread("Sub_Division_IMD_2017.csv",stringsAsFactors = T)
summary(data)
data_clean = data[complete.cases(data),]
data_na = data[!complete.cases(data),]
data_na
colnames(data)
y <- ts(data_clean[SUBDIVISION=="Bihar",c("YEAR","ANNUAL")], start=min(data_clean$YEAR), frequency=12)
autoplot(y) +
ggtitle("Annual Rain Fall by Year") +
ylab("Annual Rain Fall") +
xlab("Year")
plot(diff(y))
plot(y)
ggseasonplot(y, year.labels=TRUE, year.labels.left=TRUE) +
ylab("$ million") +
ggtitle("Seasonal plot: antidiabetic drug sales")
library(data.table)
library(ggplot2)
library(plotly)
#install.packages("fpp")
library(fpp)
library(forecast)
data<-fread("Sub_Division_IMD_2017.csv",stringsAsFactors = T)
summary(data)
data_clean = data[complete.cases(data),]
data_na = data[!complete.cases(data),]
data_na
colnames(data)
y <- ts(data_clean[SUBDIVISION=="Bihar",c("YEAR","ANNUAL")], start=min(data_clean$YEAR), frequency=12)
autoplot(y) +
ggtitle("Annual Rain Fall by Year") +
ylab("Annual Rain Fall") +
xlab("Year")
plot(diff(y))
plot(y)
ggseasonplot(y, year.labels=TRUE, year.labels.left=TRUE) +
ylab("$ million") +
ggtitle("Seasonal plot: antidiabetic drug sales")
df_ts <- xts(x = data_clean, order.by = data_clean$YEAR)
library(forecast)
#arima_fit = auto.arima(adenoTS[,2])
model_Arima<-auto.arima(y)
model_holtwinters<-HoltWinters(y)
plot(forecast(model_holtwinters))
View(y)
y <- ts(data_clean[,c("YEAR","ANNUAL")], start=min(data_clean$YEAR), frequency=12)
autoplot(y) +
ggtitle("Annual Rain Fall by Year") +
ylab("Annual Rain Fall") +
xlab("Year")
plot(diff(y))
plot(y)
ggseasonplot(y, year.labels=TRUE, year.labels.left=TRUE) +
ylab("$ million") +
ggtitle("Seasonal plot: antidiabetic drug sales")
library(forecast)
#arima_fit = auto.arima(adenoTS[,2])
model_Arima<-auto.arima(y)
library(forecast)
#arima_fit = auto.arima(adenoTS[,2])
model_Arima<-auto.arima(y)
View(data_na)
View(data)
View(data_clean)
View(data_na)
View(data_na)
View(data_na)
