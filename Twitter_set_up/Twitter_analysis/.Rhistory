library("twitteR")
#install.packages("ROAuth")
library(ROAuth)
#install.packages("NLP")
library("NLP")
library("twitteR")
#install.packages("syuzhet")
library("syuzhet")
#install.packages("tm")
library("tm")
#install.packages("SnowballC")
library("SnowballC")
#install.packages("stringi")
library("stringi")
#install.packages("topicmodels")
library("topicmodels")
#install.packages("syuzhet")
library("syuzhet")
#install.packages("ROAuth")
library("ROAuth")
install.packages("wordcloud")
library("wordcloud")
library("twitteR")
#install.packages("ROAuth")
library(ROAuth)
#install.packages("NLP")
library("NLP")
library("twitteR")
#install.packages("syuzhet")
library("syuzhet")
#install.packages("tm")
library("tm")
#install.packages("SnowballC")
library("SnowballC")
#install.packages("stringi")
library("stringi")
#install.packages("topicmodels")
library("topicmodels")
#install.packages("syuzhet")
library("syuzhet")
#install.packages("ROAuth")
library("ROAuth")
#install.packages("wordcloud")
library("wordcloud")
install.packages("wordcloud")
library("wordcloud")
library("twitteR")
#install.packages("ROAuth")
library(ROAuth)
#install.packages("NLP")
library("NLP")
library("twitteR")
#install.packages("syuzhet")
library("syuzhet")
#install.packages("tm")
library("tm")
#install.packages("SnowballC")
library("SnowballC")
#install.packages("stringi")
library("stringi")
#install.packages("topicmodels")
library("topicmodels")
#install.packages("syuzhet")
library("syuzhet")
#install.packages("ROAuth")
library("ROAuth")
#install.packages("wordcloud")
library("wordcloud")
library(ggplot2)
library(plotly)
library(dplyr)
library(data.table)
#load credentials
consumer_key<-"p0f5zNiHE476kdUPHF2cGXyLM"
consumer_secret<-"bTtTNK8s0oAIUaJrmb7JNUqGFuMY3ekZJ20UdmoZRe5F1DDwgO"
access_token<- "817441188466671616-8m3FPiGo3T6ILUcFhdgLSLxXg7kT3ol"
access_secret<- "a5wg4JaREyFXigSwc6jkfooICG8BZLkltmqEaqUU69scT"
#set up to authenticate
setup_twitter_oauth(consumer_key ,consumer_secret,access_token ,access_secret)
#fetch tweets associated with that hashtag , 12 tweets-n in
#(en)glish-lang since the indicated date yy/mm/dd
tweets <-twitteR::searchTwitter("#Machine Learning",n =10000,lang ="en",since='2018-01-01')
#strip retweets
strip_retweets(tweets)
#convert to data frame using the twListtoDF function
df <- twListToDF(tweets)#extract the data frame save it locally
saveRDS(df, file= "tweets.rds")
#convert all text to lower case
df_lower<- tolower(df$text)
# Replace blank space (“rt”)
df_lower <- gsub("rt", "", df_lower)
# Replace @UserName
df_lower <- gsub("@\\w+", "", df_lower)
# Remove punctuation
df_lower <- gsub("[[:punct:]]", "", df_lower)
# Remove links
df_lower <- gsub("http\\w+", "", df_lower)
# Remove tabs
df_lower<- gsub("[ |\t]{2,}", "", df_lower)
# Remove blank spaces at the beginning
df_lower <- gsub("^ ", "", df_lower)
# Remove blank spaces at the end
df_lower <- gsub(" $", "",df_lower )
#clean up by removing stop words
corpus<-Corpus(VectorSource(df_lower))
corpus <- tm_map(corpus, function(x)removeWords(x,stopwords()))
#generate wordcloud
wordcloud(corpus,min.freq = 10,colors=brewer.pal(8, "Dark2"),random.color = TRUE,max.words = 500)
#getting emotions using in-built function
mysentiment<-get_nrc_sentiment((df_lower))
#calculationg total score for each sentiment
Sentimentscores<-data.frame(colSums(mysentiment[,]))
names(Sentimentscores)<-"Score"
Sentimentscores<-cbind("sentiment"=rownames(Sentimentscores),Sentimentscores)
rownames(Sentimentscores)<-NULL
#plotting the sentiments with scores
ggplotly(ggplot(data=Sentimentscores,aes(x=reorder(sentiment,Score),y=Score))+geom_bar(aes(fill=sentiment),stat = "identity")+
theme(legend.position="none")+
xlab("Sentiments")+ylab("scores")+ggtitle("Sentiments of people behind the tweets on #MachineLearning")+labs(title = "Sentiments of people behind the tweets on #MachineLearning",x="Sentiments", y = "Scores")+theme(plot.title = element_text(hjust = -10,face = "bold",color = "black"))+coord_flip())
dtm <- TermDocumentMatrix(corpus)
m <- as.matrix(dtm)
v <- sort(rowSums(m),decreasing=TRUE)
d <- data.frame(word = names(v),freq=v)
d<-as.data.table(d)
d<- d[with(d,order(-freq)),]
head(d, 20)
ggplotly(ggplot(d[1:10,],aes(x=reorder(word,freq),y=freq,fill=as.factor(word)))+geom_bar(stat = "identity")+ geom_text(aes(label=freq), vjust=10)+labs(title = "The Top 10 frequently used words",x="Words", y = "Frequency of Words",fill="Words")+theme(plot.title = element_text(hjust = -10,face = "bold",color = "black"))+coord_flip())
#Donet chart which display the percentage of each class in the column
p <- d[1:10,] %>%
group_by(word) %>%
plot_ly(labels = ~word, values = ~d[1:10,freq]) %>%
add_pie(hole = 0.6) %>%
layout(title = "The Percentage of top 10 frequently occuring words.",  showlegend = F,
yaxis = list(showgrid = FALSE, zeroline = FALSE, showticklabels = FALSE))
p
library("twitteR")
#install.packages("ROAuth")
library(ROAuth)
#install.packages("NLP")
library("NLP")
library("twitteR")
#install.packages("syuzhet")
library("syuzhet")
#install.packages("tm")
library("tm")
#install.packages("SnowballC")
library("SnowballC")
#install.packages("stringi")
library("stringi")
#install.packages("topicmodels")
library("topicmodels")
#install.packages("syuzhet")
library("syuzhet")
#install.packages("ROAuth")
library("ROAuth")
#install.packages("wordcloud")
library("wordcloud")
library(ggplot2)
library(plotly)
library(dplyr)
library(data.table)
#load credentials
consumer_key<-"p0f5zNiHE476kdUPHF2cGXyLM"
consumer_secret<-"bTtTNK8s0oAIUaJrmb7JNUqGFuMY3ekZJ20UdmoZRe5F1DDwgO"
access_token<- "817441188466671616-8m3FPiGo3T6ILUcFhdgLSLxXg7kT3ol"
access_secret<- "a5wg4JaREyFXigSwc6jkfooICG8BZLkltmqEaqUU69scT"
#set up to authenticate
setup_twitter_oauth(consumer_key ,consumer_secret,access_token ,access_secret)
#fetch tweets associated with that hashtag , 12 tweets-n in
#(en)glish-lang since the indicated date yy/mm/dd
tweets <-twitteR::searchTwitter("@NMFinancial",n =10000,lang ="en",since='2018-01-01')
#strip retweets
strip_retweets(tweets)
library("twitteR")
#install.packages("ROAuth")
library(ROAuth)
#install.packages("NLP")
library("NLP")
library("twitteR")
#install.packages("syuzhet")
library("syuzhet")
#install.packages("tm")
library("tm")
#install.packages("SnowballC")
library("SnowballC")
#install.packages("stringi")
library("stringi")
#install.packages("topicmodels")
library("topicmodels")
#install.packages("syuzhet")
library("syuzhet")
#install.packages("ROAuth")
library("ROAuth")
#install.packages("wordcloud")
library("wordcloud")
library(ggplot2)
library(plotly)
library(dplyr)
library(data.table)
#load credentials
consumer_key<-"p0f5zNiHE476kdUPHF2cGXyLM"
consumer_secret<-"bTtTNK8s0oAIUaJrmb7JNUqGFuMY3ekZJ20UdmoZRe5F1DDwgO"
access_token<- "817441188466671616-8m3FPiGo3T6ILUcFhdgLSLxXg7kT3ol"
access_secret<- "a5wg4JaREyFXigSwc6jkfooICG8BZLkltmqEaqUU69scT"
#set up to authenticate
setup_twitter_oauth(consumer_key ,consumer_secret,access_token ,access_secret)
#fetch tweets associated with that hashtag , 12 tweets-n in
#(en)glish-lang since the indicated date yy/mm/dd
tweets <-twitteR::searchTwitter("@NMFinancial",n =10000,lang ="en",since='2018-01-01')
#strip retweets
strip_retweets(tweets)
#convert to data frame using the twListtoDF function
df <- twListToDF(tweets)#extract the data frame save it locally
saveRDS(df, file= "tweets.rds")
